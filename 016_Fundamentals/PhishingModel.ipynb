{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb48cc8c-51e2-44ff-82dd-6036b819f637",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/RiverGumSecurity/AILabs/blob/main/016_Fundamentals/PhishingModel.ipynb\" target=\"_new\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a527797b-bcb0-4a69-907f-f545e604296c",
   "metadata": {},
   "source": [
    "## Hugging Face: Phishing Classification Model\n",
    "\n",
    "In this lab/demo, we are going to use a pre-trained AI classification model for email phishing. This model is able to\n",
    "injest text or html data, and classify it as either \"benign\" or \"phishing\". This pre-trained model leverages BERT from Google\n",
    "which was trained in 2018. The concept of leveraging BERT, a natural language processing (NLP) model, and extending the training for \n",
    "a specific task is known as **transfer learning**.\n",
    "\n",
    "It is important to understand that a tremendous amount of the statistical and mathematical operations needed to build and use AI models are being abstracted away when you use a pre-trained model interface/API. This is actually a good thing for us, as training your own model is a specialized skill that requires some understanding of the underlying statistical theory, and even better, an understanding of the underlying linear algebra that is commonly used for all vector based computational neural networks.\n",
    "\n",
    "A common concept in natural language processing (NLP) is the idea of **tokenizing**. In it's simplest form, **tokenizing** is a process whereby string tokens (words or individual characters) are turned into mathematical vectors, otherwize known as matricies for ease of numerical computation. Since either words, or sentences do not have a fixed length, and a fixed two dimensional array (matrix) does have a limit, then we often are in the situation of truncating or padding data when performing the **tokenizing** process.\n",
    "\n",
    "In this first Jupyter notebook cell, we use the huggingface_hub, and transformers Python modules. Both are designed to facilitate the download and use of pre-trained AI models. Some points to note as follows:\n",
    "\n",
    "* [**huggingface_hub.snapshot_download()**](https://huggingface.co/docs/huggingface_hub/v0.24.2/en/package_reference/file_download#huggingface_hub.snapshot_download) is used to download a snapshot of the entire AI model repository.\n",
    "* [**transformers.AutoTokenizer.from_pretrained()**](https://huggingface.co/docs/transformers/v4.43.0/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained) is used to create a text tokenizer object from a pre-trained model.\n",
    "* [**transformers.AutoModelForSequenceClassification.from_pretrained()**](https://huggingface.co/docs/transformers/v4.43.0/en/model_doc/auto#transformers.AutoModelForSequenceClassification) is used to create a model object from which predictions can be made.\n",
    "* [**transformers.pipeline()**](https://huggingface.co/docs/transformers/en/main_classes/pipelines) is a very high level powerful functional abstraction that allows you to feed input data to an AI model for a prediction without the complex statistical API calls which are being used within the pipeline() abstraction.\n",
    "    * Please note the function argument **device='mps'** is included so that the pipeline leverages the MacOS MPS GPU core for processing.\n",
    " \n",
    "### **bert-finetuned-phishing** Model Accuracy Claims\n",
    "\n",
    "According to the hugging face published document, this model achieves the following results on the evaluation dataset:\n",
    "\n",
    "* Loss: 0.1953\n",
    "* Accuracy: 0.9717\n",
    "* Precision: 0.9658\n",
    "* Recall: 0.9670\n",
    "* False Positive Rate: 0.0249\n",
    "\n",
    "### Our Goals\n",
    "\n",
    "Analyze the original training dataset, and evaluate from an alternative dataset whether this accuracy claim seems\n",
    "correct to us. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86533022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Data will be processed on [mps] architecture.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b020a13863b2453bb87f1b85d639704b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Model downloaded to: /Users/stimpie/.cache/huggingface/hub/models--ealvaradob--bert-finetuned-phishing/snapshots/fa8fb73a007174c410ab7160d4e4c6e6b8d998d4\n",
      "[+] Prediction pipeline is ready.\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "## Hugging Face Phishing Model Demo\n",
    "## Author: Joff Thyer, Copyright (c) July 2024\n",
    "#################################################\n",
    "\n",
    "import pathlib\n",
    "import sys\n",
    "import subprocess\n",
    "import torch\n",
    "import huggingface_hub\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Ensure 'datasets' is installed\n",
    "try:\n",
    "    from datasets import Dataset, load_dataset\n",
    "except ImportError:\n",
    "    print(\"[*] Installing 'datasets' package...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"datasets\"])\n",
    "    from datasets import Dataset, load_dataset\n",
    "\n",
    "# Load Hugging Face API key\n",
    "HF_APIKEY = ''\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import userdata\n",
    "    HF_APIKEY = userdata.get('HF_APIKEY')\n",
    "else:\n",
    "    try:\n",
    "        with open(pathlib.Path.home() / '.hfkey') as hf:\n",
    "            HF_APIKEY = hf.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "if not HF_APIKEY:\n",
    "    print('[-] ERROR: Cannot continue without Hugging Face API Key')\n",
    "    sys.exit(1)\n",
    "\n",
    "# Detect available device\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = 'mps'  # Apple Silicon (M1/M2/M3)\n",
    "elif torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(f'[*] Data will be processed on [{device}] architecture.')\n",
    "\n",
    "# Download the model from Hugging Face Hub\n",
    "model_name = \"ealvaradob/bert-finetuned-phishing\"\n",
    "dpath = huggingface_hub.snapshot_download(repo_id=model_name, token=HF_APIKEY)\n",
    "print(f'[+] Model downloaded to: {dpath}')\n",
    "\n",
    "# Load tokenizer and model (no `device` argument!)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(dpath)\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(dpath)\n",
    "\n",
    "# Map device string to PyTorch index for pipeline\n",
    "if device == 'cuda':\n",
    "    device_index = 0\n",
    "elif device == 'mps':\n",
    "    device_index = torch.device(\"mps\")\n",
    "else:\n",
    "    device_index = -1  # CPU\n",
    "\n",
    "# Create the prediction pipeline\n",
    "predict = transformers.pipeline(\n",
    "    'text-classification',\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device_index if isinstance(device_index, int) else -1  # pipeline doesn't yet support torch.device(\"mps\")\n",
    ")\n",
    "\n",
    "print(\"[+] Prediction pipeline is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb9b8bf0-3f9d-4031-9ff9-c60131b39f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset: (69909, 2)\n",
      "test dataset: (7768, 2)\n"
     ]
    }
   ],
   "source": [
    "# original training dataset loaded here.\n",
    "dataset = load_dataset(\"ealvaradob/phishing-dataset\", \"combined_reduced\", trust_remote_code=True)\n",
    "tempdf = dataset['train'].to_pandas()\n",
    "train, test = train_test_split(tempdf, test_size=0.10, random_state=42)\n",
    "test.replace({'label': 0}, 'benign', inplace=True)\n",
    "test.replace({'label': 1}, 'phishing', inplace=True)\n",
    "\n",
    "train, test = Dataset.from_pandas(train, preserve_index=False), Dataset.from_pandas(test, preserve_index=False)\n",
    "print(f'train dataset: {train.shape}')\n",
    "print(f'test dataset: {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afce370b-e36a-402f-8144-527ea865c0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm  # optional for progress bar\n",
    "\n",
    "def batch_predictor(ds, infield, match, outfield, batch_size=256, labels=False, max_length=512):\n",
    "    res = []\n",
    "    data = DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
    "    for i, batch in enumerate(tqdm(data, desc=\"Predicting batches\")):\n",
    "        # Extract texts and truncate to max_length chars approx (simple heuristic)\n",
    "        texts = [t[:max_length*4] for t in batch[infield]]  # rough char truncation\n",
    "        \n",
    "        # Use pipeline with truncation and max_length to safely handle long sequences\n",
    "        preds = predict(texts, truncation=True, max_length=max_length, padding=True)\n",
    "        \n",
    "        if labels:\n",
    "            res.extend(preds)  # return full prediction dicts\n",
    "        else:\n",
    "            # Compare predicted label to match label (case-insensitive)\n",
    "            res.extend([p['label'].lower() == match.lower() for p in preds])\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0020aa-a045-49b8-8ff4-4c6c66d58b10",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "A confusion matrix is a table used to evaluate the performance of a classification algorithm. It is particularly useful for understanding how well a classifier is distinguishing between classes, especially in binary classification. The matrix compares the actual target values with the values predicted by the model. Hereâ€™s a breakdown of the components of a confusion matrix for binary classification.\n",
    "\n",
    "Components:\n",
    "* True Positive (TP): The number of instances correctly predicted as positive.\n",
    "* True Negative (TN): The number of instances correctly predicted as negative.\n",
    "* False Positive (FP): The number of instances incorrectly predicted as positive (Type I error).\n",
    "* False Negative (FN): The number of instances incorrectly predicted as negative (Type II error).\n",
    "\n",
    "In the case of phishing classification, we have a binary classifier, thus the components break down as:\n",
    "* True Positive (TP): correctly classified as spam.\n",
    "* True Negative (TN): correctly classified as not spam.\n",
    "* False Positive (FP): incorrectly classified as spam.\n",
    "* False Negative (FN): incorrectly classified as not spam.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d60c9433-f401-4e70-b3b7-4b3340bdbf10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233a339baade472b8ba42391d7805cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting batches:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# confusion matrix example using test/train split.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m y_test \u001b[38;5;241m=\u001b[39m [t[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphishing\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m test]\n\u001b[0;32m----> 3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mphishing\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred)\n\u001b[1;32m      6\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m (cm[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m cm[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m test\u001b[38;5;241m.\u001b[39mnum_rows\n",
      "Cell \u001b[0;32mIn[11], line 12\u001b[0m, in \u001b[0;36mbatch_predictor\u001b[0;34m(ds, infield, match, outfield, batch_size, labels, max_length)\u001b[0m\n\u001b[1;32m      9\u001b[0m texts \u001b[38;5;241m=\u001b[39m [t[:max_length\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m batch[infield]]  \u001b[38;5;66;03m# rough char truncation\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Use pipeline with truncation and max_length to safely handle long sequences\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels:\n\u001b[1;32m     15\u001b[0m     res\u001b[38;5;241m.\u001b[39mextend(preds)  \u001b[38;5;66;03m# return full prediction dicts\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:159\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03mClassify the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    158\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (inputs,)\n\u001b[0;32m--> 159\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/transformers/pipelines/base.py:1283\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[1;32m   1280\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   1281\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1282\u001b[0m     )\n\u001b[0;32m-> 1283\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m    124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[0;32m--> 125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/transformers/pipelines/base.py:1209\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1208\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1209\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:190\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(model_forward)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    189\u001b[0m     model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1668\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1661\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1662\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1663\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1665\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1668\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1674\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1675\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1676\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1680\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1682\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    686\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         output_attentions,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    575\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    584\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:524\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    507\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    514\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    515\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[1;32m    516\u001b[0m         hidden_states,\n\u001b[1;32m    517\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m         output_attentions,\n\u001b[1;32m    523\u001b[0m     )\n\u001b[0;32m--> 524\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466\u001b[0m, in \u001b[0;36mBertSelfOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 466\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    468\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lab16/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# confusion matrix example using test/train split.\n",
    "y_test = [t['label'] == 'phishing' for t in test]\n",
    "y_pred = batch_predictor(test, 'text', 'phishing', 'label', batch_size=256)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "accuracy = (cm[0][0] + cm[1][1]) / test.num_rows\n",
    "print(f'\\r\\n[*] Calculated Model Accuracy = {accuracy:02f}')\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Negative', 'Positive'])\n",
    "_ = disp.plot(cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9458d15b-50b4-4fbb-b498-f07b5ede037a",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "The Python module **Pandas** is an important and powerful module being used in data science.\n",
    "Pandas provides two core concepts as Python classes known as a **Dataframe**, and a **Series**.\n",
    "For natural language processing tasks, the **Dataframe** class is very commonly used.\n",
    "In the below cell we are reading a dataset from a comma delimited file, replacing some column names, and then collecting some sample data from the data frame in order to make AI model predictions from that sample data.\n",
    "\n",
    "* we import pandas and a common convention in data science is to alias it as **pd** in Python scripts\n",
    "* in the code below we create two dataframes, \"**source**\" contains the full phishing email comma delimited dataset while \"**df**\" contains a subset that is sampled from the source.\n",
    "* [**pd.read_csv()**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) is commonly used to read and process comma delimited data. It has many options as you can read in the documentation link, and it nicely allows you to use either a file name or URL to read data from.\n",
    "* [**pd.dropna()**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html) is used to drop any rows with NULL data in the dataframe. Using **inplace=True** allows us to mutate the dataframe inplace rather than having to assign the result to a new object.\n",
    "* [**pd.replace()**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html) is a very useful function for searching and replace data in an entire dataframe. It can perform simple string replacement or even use regular expressions if you have the need for more complex operations.\n",
    "    * In our use case, the AI model we are using on prediction returns either the string \"**phishing**\" or \"**benign**\".\n",
    "    * In the phishing labelled dataset, the labels are either \"**Phishing Email**\" or \"**Safe Email**\".\n",
    "    * It is desirable to have the same nomenclature thus we use *replace* to fix this discrepency.\n",
    "* [**pd.sample()**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html) allows us to take a sampling from a dataframe and return another dataframe. We choose a sample size that is manageable in terms of the real time execution time elapsed when making AI model predictions.\n",
    "    * AI model predictions require linear algebraic computation which is always best performed on a vector processor design architecture such as Nvidia (CUDA based) Graphics Processing Units (GPU), or the [MacBook Pro M3 Meta Performance Shader (MPS) core](https://developer.apple.com/videos/play/tech-talks/111375/).\n",
    "    * Pure CPU based calculation alone does work but is orders of magnitude slower.\n",
    "* [**pd.assign()**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.assign.html) is used to create a new column in the dataframe. In our use case this new column will become the prediction from the AI model so that we can store the prediction back to the same dataframe. We use a Python lambda function to create the number of rows in the new column to be the same as the length of the sampled dataframe structure.\n",
    "* [**pd.shape**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html) is an attribute of the dataframe class that contains the **(rows, columns)** in the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48ffb45f-befd-44f1-9774-e42e029ef15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the entire phishing dataset is: (18634, 3)\n",
      "The shape of the sampled data frame is: (6000, 5)\n"
     ]
    }
   ],
   "source": [
    "source = pd.read_csv('https://github.com/RiverGumSecurity/Datasets/raw/main/Kaggle/Phishing_Email.csv.gz')\n",
    "source.dropna(inplace=True)\n",
    "source = source.replace('Phishing Email', 'phishing')\n",
    "source = source.replace('Safe Email', 'benign')\n",
    "\n",
    "sample_size = 6000\n",
    "df = source.sample(sample_size)\n",
    "df = df.assign(Prediction = lambda x: [None] * len(df))\n",
    "df = df.assign(Score = lambda x: [None] * len(df))\n",
    "\n",
    "print(f'The shape of the entire phishing dataset is: {source.shape}')\n",
    "print(f'The shape of the sampled data frame is: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccac07b1-274b-4efd-b782-a7b353b51ca6",
   "metadata": {},
   "source": [
    "## Making the AI Model do some predictive work!\n",
    "\n",
    "This is where the rubber meets the road.  In the code below, we are looping through all of the data in our sampled \"**df**\" dataframe\n",
    "and making some predictions using the \"**predict**\" pipeline object we created at the start of this notebook.\n",
    "A few highlights to point out here:\n",
    "* the logic within the loop uses an arbritrary random integer to print out a progress count of sorts. It is meaningless with regard to the actual prediction\n",
    "* the \"**predict**\" object is passed the actual textual data and returns a Python dictionary inside a Python list. The dictionary has both a \"**score**\" and a \"**label**\" key in it. Since the label is a binary classification of *phishing* or *benign*, we only care about storing this result of the prediction using the \"**label**\" key to retrieve it.\n",
    "* the Pandas [**pd.iat()**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iat.html) method is used to assign the resulting prediction label to a specific row number in the dataframe.\n",
    "* the Python exception logic allows us to continue making predictions if there is some unknown failure at any specific row. It also allows us to catch the **KeyboardInterrupt** exception so that we can terminate the prediction loop early if we feel it is taking too long.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b62ef117-d927-430c-a470-facf32eadc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of tensor a (1927) must match the size of tensor b (512) at non-singleton dimension 1\n",
      "\n",
      "[+] Number of prediction / label mismatches: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Email Text</th>\n",
       "      <th>Email Type</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11671</th>\n",
       "      <td>11672</td>\n",
       "      <td>cp name change / merger list for 2 / 2000 this...</td>\n",
       "      <td>benign</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4719</th>\n",
       "      <td>4719</td>\n",
       "      <td>hotlist louise , attached is the hotlist based...</td>\n",
       "      <td>benign</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13149</th>\n",
       "      <td>13150</td>\n",
       "      <td>wharton tiger team vince and kristin , i forwa...</td>\n",
       "      <td>benign</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3672</th>\n",
       "      <td>3672</td>\n",
       "      <td>Today's Headlines from The Register\\n---------...</td>\n",
       "      <td>benign</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6250</th>\n",
       "      <td>6250</td>\n",
       "      <td>It's got to be razor 2.x...I've never installe...</td>\n",
       "      <td>benign</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>1504</td>\n",
       "      <td>ld ' 98 - call for participation ld ' 98 the f...</td>\n",
       "      <td>benign</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10833</th>\n",
       "      <td>10834</td>\n",
       "      <td>new albany - regulatory approvals louise , don...</td>\n",
       "      <td>benign</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15438</th>\n",
       "      <td>15439</td>\n",
       "      <td>Problem with spamtrap\\nCould not lock /home/yy...</td>\n",
       "      <td>benign</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>1819</td>\n",
       "      <td>The following domains that are registered as b...</td>\n",
       "      <td>benign</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6018</th>\n",
       "      <td>6018</td>\n",
       "      <td>dec 00 daren - i need to get with you to find ...</td>\n",
       "      <td>benign</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                         Email Text  \\\n",
       "11671       11672  cp name change / merger list for 2 / 2000 this...   \n",
       "4719         4719  hotlist louise , attached is the hotlist based...   \n",
       "13149       13150  wharton tiger team vince and kristin , i forwa...   \n",
       "3672         3672  Today's Headlines from The Register\\n---------...   \n",
       "6250         6250  It's got to be razor 2.x...I've never installe...   \n",
       "1504         1504  ld ' 98 - call for participation ld ' 98 the f...   \n",
       "10833       10834  new albany - regulatory approvals louise , don...   \n",
       "15438       15439  Problem with spamtrap\\nCould not lock /home/yy...   \n",
       "1819         1819  The following domains that are registered as b...   \n",
       "6018         6018  dec 00 daren - i need to get with you to find ...   \n",
       "\n",
       "      Email Type Prediction Score  \n",
       "11671     benign       None  None  \n",
       "4719      benign       None  None  \n",
       "13149     benign       None  None  \n",
       "3672      benign       None  None  \n",
       "6250      benign       None  None  \n",
       "1504      benign       None  None  \n",
       "10833     benign       None  None  \n",
       "15438     benign       None  None  \n",
       "1819      benign       None  None  \n",
       "6018      benign       None  None  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Model Predictions\n",
    "spin = r'\\-/|+'\n",
    "mm = 0\n",
    "\n",
    "batch = []\n",
    "batch_size = 128\n",
    "for i, row in enumerate(df['Email Text']):\n",
    "    try:\n",
    "        if i > 0 and not len(batch) % batch_size:\n",
    "            ps = predict(batch)\n",
    "            j = i - batch_size\n",
    "            for p in ps:\n",
    "                df['Prediction'].iat[j] = p['label']\n",
    "                df['Score'].iat[j] = p['score']\n",
    "                if df['Prediction'].iat[j] != df['Email Type'].iat[j]:\n",
    "                    mm += 1\n",
    "                j += 1\n",
    "            print(f'\\r[{spin[i % len(spin)]}] Processed {i} rows of data.', end='', flush=True)\n",
    "            batch = []\n",
    "            \n",
    "        # append the text into the batch list\n",
    "        batch.append(str(row))\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "print(f'\\r\\n[+] Number of prediction / label mismatches: {mm}')\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f5835c-20d0-4e02-910c-573a78f37c21",
   "metadata": {},
   "source": [
    "## Visualization with MatPlotLib\n",
    "\n",
    "Being able to produce a good plot/chart to visualize results is critical for data science work.\n",
    "Python's open source **matplotlib** does a great job for us in this area, and works very well\n",
    "within Jupyter notebook. There are two basic modes you can use **matplotlib** in, *notebook* mode, or *inline* mode. Of these,\n",
    "using it *inline* is the default and easiest method. In full *notebook* mode, there is ability to use interactive charts\n",
    "however it requires tighter Python module integration and more software dependencies.\n",
    "\n",
    "In this example, we create a single **figure**, and then use the **subplot** method to create two different\n",
    "plots within the same figure so that we can compare the results side by side. Below is a list of methods used with links to\n",
    "the related documentation.\n",
    "\n",
    "* [**plt.figure()**](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.figure.html)\n",
    "* [**plt.subplot()**](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplot.html)\n",
    "    * Note: subplot() arguments are \"rows\", \"cols\", and \"index\".\n",
    "    * in the example below, we create 1 x 2 subplots.\n",
    "* [**plt.title()**](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.title.html)\n",
    "* [**plt.xlabel()**](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.xlabel.html)\n",
    "* [**plt.ylabel()**](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.ylabel.html)\n",
    "* [**pandas.DataFrame.plot()**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfd92d91-e61b-4cef-8729-2f17e61676a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# this is the default mode however we include for good measure.\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(1, figsize=(10, 8))\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "plt.title('Labelled Frequency Counts')\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "plt.title('Predicted Frequency Counts')\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Frequency')\n",
    "_ = source['Email Type'].value_counts().plot(ax=ax1, kind='bar', color=['g', 'r'], label='SourceData', grid=True)\n",
    "\n",
    "# create a new pandas series containing our counts\n",
    "df2 = df.groupby(by = 'Prediction', as_index=True)['Prediction'].count()\n",
    "df2['mismatch'] = mm\n",
    "_ = df2.plot(ax=ax2, kind='bar', label='Prediction', color=['g', 'r', 'b'], grid=True, yticks=range(0, df2.max(), 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57209edf-0093-478b-ae49-63ae39811e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated Model Accuracy = 0.603500\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix example using sampled data.\n",
    "y_test = [t == 'phishing' for t in df['Prediction']]\n",
    "y_pred = [t == 'phishing' for t in df['Email Type']]\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "accuracy = (cm[0][0] + cm[1][1]) / len(y_test)\n",
    "print(f'Calculated Model Accuracy = {accuracy:02f}')\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Negative', 'Positive'])\n",
    "_ = disp.plot(cmap=plt.cm.Reds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbe0820-77ad-4f5d-a66d-0a484eb3efe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
